<!DOCTYPE html>
<html lang="en">
<head>
    <link href="styles.css" rel="stylesheet">
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>WebRTC Background Replacement</title>
</head>
<body>
<video id="output" autoplay playsinline></video>

<div class="optionBox">


    <div class="slider-container">
        <label for="contrastRange">Contrast</label>
        <input type="range" id="contrastRange" min="0.5" max="2" step="0.1" value="1">
    </div>

    <div class="slider-container">
        <label for="brightnessRange">Brightness</label>
        <input type="range" id="brightnessRange" min="0.5" max="2" step="0.1" value="1">
    </div>

    <div class="slider-container">
        <label for="blurRange">blur</label>
        <input type="range" id="blurRange" min="0" max="20" step="1" value="0">
    </div>

    <label class="switch">
        <input type="checkbox" id="grayScaleSwitch">
        <span class="slider"></span>
    </label>
    <span>  grayScale</span>
</div>

<div id="bg-list" style="display: flex"></div>





<video id="video1" width="640" height="480" autoplay></video>
<canvas id="output1" width="640" height="480"></canvas>

<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/body-pix"></script>
<script >
    const videoElement = document.getElementById('video1');
    const canvas = document.getElementById('output1');
    const ctx = canvas.getContext('webgl', {
        preserveDrawingBuffer: true  // Helps to keep the rendered image intact for later processing
    });
    async function setupWebcam() {
        const stream = await navigator.mediaDevices.getUserMedia({
            video: true
        });
        videoElement.srcObject = stream;
    }

    // Apply custom background after segmentation
    async function loadAndRunBodyPix() {
        const net = await bodyPix.load();
        console.log("BodyPix model loaded.");

        // Load the custom background image
        const customBackground = new Image();
        customBackground.src = './img/1.jpg'; // Ensure the path is correct

        customBackground.onload = async () => {
            // Process each frame
            const processFrame = async () => {
                const segmentation = await net.segmentPerson(videoElement,{
                    flipHorizontal: false,
                    internalResolution: 'low',
                    segmentationThreshold: 0.7
                });

                // Create an image mask from the segmentation
                const mask = bodyPix.toMask(segmentation);
                ctx.clearRect(0, 0, canvas.width, canvas.height);

                // Set the filter for contrast, brightness, and blur

                // Apply the mask to the canvas, keeping the person in the foreground

                ctx.putImageData(mask, 0, 0);
                 ctx.drawImage(videoElement, 0, 0);
                // Apply the custom background
                ctx.globalCompositeOperation = 'destination-over'; // Draw the background behind the person
                ctx.drawImage(customBackground, 0, 0, canvas.width, canvas.height);


                // ctx.filter = `brightness(1) contrast(2) blur(20px)`;

                // Continue processing the next frame
                requestAnimationFrame(processFrame);
            };

            processFrame();
        };
    }

    // Initialize everything
    setupWebcam().then(() => {
        loadAndRunBodyPix();
    });
</script>




<!--<script type="module" src="scripts.js"></script>-->

</body>
</html>
